{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pdfkit\n",
    "import sys\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import PythonMagick\n",
    "import io\n",
    "import ast\n",
    "import json\n",
    "from google.cloud.vision import types\n",
    "from google.cloud import vision\n",
    "from os.path import isfile, join\n",
    "sys.path.append('../')\n",
    "from modules.helpers.dataframe_to_json import DataframeToJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    df = pd.DataFrame()\n",
    "    page = path.split('.')[1].replace('pdf','')\n",
    "    \n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "\n",
    "    row_dict = {'WordText':None, 'PageNumber': None, 'X_Min': None, 'X_Max': None, 'Y_Min': None, 'Y_Max': None}\n",
    "    for text in texts:\n",
    "\n",
    "        row_dict['WordText'] = text.description\n",
    "\n",
    "        vertices = ([[vertex.x, vertex.y]\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "        \n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for vertex in vertices:\n",
    "            for v in vertex:\n",
    "                xlist.append(vertex[0])\n",
    "                ylist.append(vertex[1])\n",
    "        row_dict['X_Min'] = min(xlist)\n",
    "        row_dict['X_Max'] = max(xlist)\n",
    "        row_dict['Y_Min'] = min(ylist)\n",
    "        row_dict['Y_Max'] = max(ylist)\n",
    "        \n",
    "        row_dict['PageNumber'] = page\n",
    "\n",
    "        df = df.append(row_dict, ignore_index=True)\n",
    "    df = df[pd.notnull(df['WordText'])]\n",
    "    return ast.literal_eval(DataframeToJSON(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'C:/Users/juang/Documents/Stocks/'\n",
    "tickers = []\n",
    "config = pdfkit.configuration(wkhtmltopdf='C:\\Program Files\\wkhtmltopdf\\\\bin\\\\wkhtmltopdf.exe')\n",
    "files = [f for f in os.listdir(mypath) if '.html' in f]\n",
    "for f in files:\n",
    "    tickers.append(f.split('-')[0])\n",
    "    if '.html' in f and not os.path.isfile(mypath+'PDFs/'+f.split('-')[0]+'.pdf'): \n",
    "        pdf = f.split('-')[0]+'.pdf'\n",
    "        pdfkit.from_file(mypath+f, mypath+'PDFs/'+pdf, configuration=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHK', 'DIS', 'F', 'FB', 'GME', 'LLY', 'RAD', 'UPS']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 46 pages.\n"
     ]
    }
   ],
   "source": [
    "mypath = 'C:/Users/juang/Documents/Stocks/PDFs/'\n",
    "onlyfiles = [f for f in os.listdir(mypath) if isfile(join(mypath, f))]\n",
    "for f in onlyfiles:\n",
    "    directory = mypath+str(f).replace('.pdf','')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        pdffilename = f \n",
    "        pdf_im = PyPDF2.PdfFileReader(open(mypath+pdffilename, \"rb\"))\n",
    "        npage = pdf_im.getNumPages()\n",
    "        print('Converting %d pages.' % npage)\n",
    "        for p in range(npage):\n",
    "            im = PythonMagick.Image()\n",
    "            im.density('300')\n",
    "            im.read(mypath+pdffilename + '[' + str(p) +']')\n",
    "            im.write(directory+'/'+pdffilename + str(p)+ '.jpg')\n",
    "    elif not len(os.listdir(directory)) >= 1:\n",
    "        pdffilename = f \n",
    "        pdf_im = PyPDF2.PdfFileReader(open(mypath+pdffilename, \"rb\"))\n",
    "        npage = pdf_im.getNumPages()\n",
    "        print('Converting %d pages.' % npage)\n",
    "        for p in range(npage):\n",
    "            im = PythonMagick.Image()\n",
    "            im.density('300')\n",
    "            im.read(mypath+pdffilename + '[' + str(p) +']')\n",
    "            im.write(directory+'/'+pdffilename + str(p)+ '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHK\n",
      "DIS\n",
      "F\n",
      "FB\n",
      "GME\n",
      "LLY\n",
      "RAD\n",
      "UPS\n"
     ]
    }
   ],
   "source": [
    "mypath = 'C:/Users/juang/Documents/Stocks/PDFs/'\n",
    "for i in range(0, len(tickers)):\n",
    "    json_dict = {'Ticker': None, 'Pages': []}\n",
    "    json_dict['Ticker'] = tickers[i]\n",
    "    onlyfiles = [f for f in os.listdir(mypath+tickers[i].replace('.pdf',''))]\n",
    "    tickers[i] = tickers[i].replace('.pdf','')\n",
    "    print(tickers[i])\n",
    "    \n",
    "    if os.path.isfile(mypath+\"/\"+tickers[i]+\"/\"+'all'+'.json'):\n",
    "        if os.path.getsize(mypath+\"/\"+tickers[i]+\"/\"+'all'+'.json') < 100:\n",
    "            for f in onlyfiles:\n",
    "                if '.pdf' in f and os.path.getsize(mypath+\"/\"+tickers[i]+\"/\"+'all'+'.json') < 100:\n",
    "                    json_row = detect_text(mypath+tickers[i]+'/'+f)\n",
    "                    json_dict['Pages'].append(json_row)\n",
    "    \n",
    "                    with open(mypath+\"/\"+tickers[i]+\"/\"+'all'+'.json', 'w') as fp:\n",
    "                        json.dump(json_dict, fp)\n",
    "    else:\n",
    "        for f in onlyfiles:\n",
    "            json_row = detect_text(mypath+tickers[i]+'/'+f)\n",
    "            json_dict['Pages'].append(json_row)\n",
    "\n",
    "            with open(mypath+\"/\"+tickers[i]+\"/\"+'all'+'.json', 'w') as fp:\n",
    "                json.dump(json_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
